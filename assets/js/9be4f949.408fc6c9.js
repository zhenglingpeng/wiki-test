"use strict";(self.webpackChunkclassic=self.webpackChunkclassic||[]).push([[6995],{33988:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>p,frontMatter:()=>d,metadata:()=>s,toc:()=>o});const s=JSON.parse('{"id":"NeoEdge NG4500 Series/Application Guide/mediapipe","title":"Pose Estimation","description":"---","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/1-NeoEdge NG4500 Series/3-Application Guide/2-mediapipe.md","sourceDirName":"1-NeoEdge NG4500 Series/3-Application Guide","slug":"/NeoEdge NG4500 Series/Application Guide/mediapipe","permalink":"/docs/NeoEdge NG4500 Series/Application Guide/mediapipe","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"DeepSeek-R1 Local Deployment","permalink":"/docs/NeoEdge NG4500 Series/Application Guide/Deepseek-r1"},"next":{"title":"Object Detection","permalink":"/docs/NeoEdge NG4500 Series/Application Guide/Object Detection"}}');var r=i(74848),t=i(28453);const d={},a="Pose Estimation",l={},o=[{value:"1. Overview",id:"1-overview",level:2},{value:"2. System Requirements",id:"2-system-requirements",level:2},{value:"Hardware",id:"hardware",level:3},{value:"Software",id:"software",level:3},{value:"3. Environment Setup",id:"3-environment-setup",level:2},{value:"Step 1: Update the System and Install Dependencies",id:"step-1-update-the-system-and-install-dependencies",level:3},{value:"Step 2\uff1aInstall Required Python Packages",id:"step-2install-required-python-packages",level:3},{value:"4. Running Pose Estimation",id:"4-running-pose-estimation",level:2},{value:"mediapipe_pose_1",id:"mediapipe_pose_1",level:2},{value:"5. Hand Tracking",id:"5-hand-tracking",level:2},{value:"6. Performance and Optimization Tips",id:"6-performance-and-optimization-tips",level:2},{value:"Tips",id:"tips",level:3},{value:"7. Troubleshooting",id:"7-troubleshooting",level:2},{value:"8. Appendix",id:"8-appendix",level:2},{value:"References",id:"references",level:3}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"pose-estimation",children:"Pose Estimation"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"1-overview",children:"1. Overview"}),"\n",(0,r.jsxs)(n.p,{children:["This guide demonstrates how to perform ",(0,r.jsx)(n.strong,{children:"real-time pose estimation"})," on the ",(0,r.jsx)(n.strong,{children:"Jetson Orin"})," platform (Nano / NX / AGX) using the ",(0,r.jsx)(n.strong,{children:"MediaPipe Python API"}),", with GPU acceleration enabled (if supported)."]}),"\n",(0,r.jsx)(n.p,{children:"Pose estimation is widely used in applications such as gesture recognition, fitness tracking, and human-computer interaction."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"mediapipe-series-solutions",src:i(66507).A+"",width:"600",height:"281"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"2-system-requirements",children:"2. System Requirements"}),"\n",(0,r.jsx)(n.h3,{id:"hardware",children:"Hardware"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Jetson Orin series (Nano\uff0cNX\uff09"}),"\n",(0,r.jsx)(n.li,{children:"USB or CSI camera (Optional but recommended)"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"software",children:"Software"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Operating System"}),"\uff1aUbuntu 20.04 / 22.04 LTS\uff08Base on JetPack\uff09"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"JetPack"}),"\uff1aOfficial NVIDIA image (includes CUDA, cuDNN, TensorRT)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Python"}),"\uff1aVersion 3.8 or higher recommended"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"MediaPipe\uff08Python\uff09"}),"\uff1aInstall via ",(0,r.jsx)(n.code,{children:"pip"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Dependencies"}),"\uff1aOpenCV\uff0cFFmpeg\uff0cGStreamer(for camera/video support)"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"3-environment-setup",children:"3. Environment Setup"}),"\n",(0,r.jsx)(n.h3,{id:"step-1-update-the-system-and-install-dependencies",children:"Step 1: Update the System and Install Dependencies"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"sudo apt update && sudo apt upgrade\r\nsudo apt install -y \\\r\n    python3-dev python3-pip python3-opencv \\\r\n    libopencv-dev \\\r\n    libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev \\\r\n    libavcodec-dev libavformat-dev libswscale-dev\n"})}),"\n",(0,r.jsx)(n.h3,{id:"step-2install-required-python-packages",children:"Step 2\uff1aInstall Required Python Packages"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"python3 -m pip install --upgrade pip\r\npip3 install mediapipe opencv-python\n"})}),"\n",(0,r.jsx)(n.p,{children:"To enable GPU acceleration using TensorRT and CUDA (included with JetPack), and to maximize system performance:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"sudo nvpmodel -m 0\r\nsudo jetson_clocks\n"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"4-running-pose-estimation",children:"4. Running Pose Estimation"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"pose",src:i(81132).A+"",width:"772",height:"438"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import cv2\r\nimport mediapipe as mp\r\n\r\nmp_pose = mp.solutions.pose\r\npose = mp_pose.Pose()\r\n\r\ncap = cv2.VideoCapture(0)\r\nwhile True:\r\n    ret, frame = cap.read()\r\n    if not ret:\r\n        break\r\n    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\r\n    results = pose.process(image)\r\n\r\n    if results.pose_landmarks:\r\n        mp.solutions.drawing_utils.draw_landmarks(\r\n            frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\r\n    \r\n    cv2.imshow("Pose Estimation", frame)\r\n    if cv2.waitKey(5) & 0xFF == 27:\r\n        break\r\ncap.release()\r\ncv2.destroyAllWindows()\n'})}),"\n",(0,r.jsx)(n.h2,{id:"mediapipe_pose_1",children:(0,r.jsx)(n.img,{alt:"mediapipe_pose_1",src:i(50229).A+"",width:"640",height:"480"})}),"\n",(0,r.jsx)(n.h2,{id:"5-hand-tracking",children:"5. Hand Tracking"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"hand",src:i(52964).A+"",width:"709",height:"247"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import cv2\r\nimport mediapipe as mp\r\nimport time\r\n\r\nmp_hands = mp.solutions.hands\r\nhands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)\r\nmp_drawing = mp.solutions.drawing_utils\r\n\r\ncap = cv2.VideoCapture(0)\r\n\r\nwhile cap.isOpened():\r\n    ret, frame = cap.read()\r\n    if not ret:\r\n        continue\r\n    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\r\n    results = hands.process(image)\r\n    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\r\n\r\n    if results.multi_hand_landmarks:\r\n        for hand_landmarks in results.multi_hand_landmarks:\r\n            mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\r\n\r\n    cv2.imshow(\"Hand Tracking\", image)\r\n\r\n    if cv2.waitKey(1) & 0xFF == ord('q'):\r\n        break\r\n\r\ncap.release()\r\ncv2.destroyAllWindows()\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"hand",src:i(16205).A+"",width:"640",height:"480"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"6-performance-and-optimization-tips",children:"6. Performance and Optimization Tips"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Mode"}),(0,r.jsx)(n.th,{children:"FPS\uff08AGX Orin\uff09"}),(0,r.jsx)(n.th,{children:"GPU Usage"}),(0,r.jsx)(n.th,{children:"Acceleration"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Default (CPU)"}),(0,r.jsx)(n.td,{children:"~5\u201310 FPS"}),(0,r.jsx)(n.td,{children:"Low"}),(0,r.jsx)(n.td,{children:"\u274c"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"JetPack GPU"}),(0,r.jsx)(n.td,{children:"~25\u201340 FPS"}),(0,r.jsx)(n.td,{children:"Moderate"}),(0,r.jsx)(n.td,{children:"\u2705"})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"tips",children:"Tips"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Use ",(0,r.jsx)(n.code,{children:"jetson_clocks"})," and set",(0,r.jsx)(n.code,{children:"nvpmodel"})," to maximum performance mode"]}),"\n",(0,r.jsx)(n.li,{children:"Use multithreaded frame capture with OpenCV"}),"\n",(0,r.jsx)(n.li,{children:"Reduce input resolution (e.g., 640\xd7480) to improve frame rate"}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"7-troubleshooting",children:"7. Troubleshooting"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Issue"}),(0,r.jsx)(n.th,{children:"Solution"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Import error"}),(0,r.jsxs)(n.td,{children:["Ensure ",(0,r.jsx)(n.code,{children:"mediapipe"}),"  is installed via ",(0,r.jsx)(n.code,{children:" pip"})]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Camera not detected"}),(0,r.jsxs)(n.td,{children:["Manually test with  ",(0,r.jsx)(n.code,{children:"cv2.VideoCapture(0)"})]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Low FPS"}),(0,r.jsx)(n.td,{children:"Enable GPU acceleration, lower image resolution, disable drawing"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Cannot display window"}),(0,r.jsxs)(n.td,{children:["For SSH users, run ",(0,r.jsx)(n.code,{children:"export DISPLAY=:0"})," or use VNC"]})]})]})]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"8-appendix",children:"8. Appendix"}),"\n",(0,r.jsx)(n.h3,{id:"references",children:"References"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://github.com/google/mediapipe",children:"MediaPipe GitHub"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://github.com/google-ai-edge/mediapipe-samples",children:"MediaPipe Samples"})}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},66507:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/mediapipe-series-solutions-c06c20579e9664ba4afc5961e047fa44.gif"},52964:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/mediapipe_hand_0-5ddb92345b27ac365af9dec69096aec5.png"},16205:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/mediapipe_hand_1-ee7a7c08de6ed5faaf55d81c1e7237c0.png"},81132:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/mediapipe_pose_0-f1579209217a3fc9b11d7275f4375843.png"},50229:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/mediapipe_pose_1-3878ff7c2f7da7d4a2555267be20cde6.png"},28453:(e,n,i)=>{i.d(n,{R:()=>d,x:()=>a});var s=i(96540);const r={},t=s.createContext(r);function d(e){const n=s.useContext(t);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:d(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);