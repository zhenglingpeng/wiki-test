"use strict";(self.webpackChunkclassic=self.webpackChunkclassic||[]).push([[8139],{43271:(e,l,n)=>{n.r(l),n.d(l,{assets:()=>t,contentTitle:()=>o,default:()=>h,frontMatter:()=>i,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"NeoEdge NG4500 Series/NG4500-CB01 Development Board/Software Guide/Software Frameworks and Tools/ollama","title":"Ollama","description":"---","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/1-NeoEdge NG4500 Series/2-NG4500-CB01 Development Board/2-Software Guide/3-Software Frameworks and Tools/1-ollama.md","sourceDirName":"1-NeoEdge NG4500 Series/2-NG4500-CB01 Development Board/2-Software Guide/3-Software Frameworks and Tools","slug":"/NeoEdge NG4500 Series/NG4500-CB01 Development Board/Software Guide/Software Frameworks and Tools/ollama","permalink":"/wiki-test/docs/NeoEdge NG4500 Series/NG4500-CB01 Development Board/Software Guide/Software Frameworks and Tools/ollama","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Docker","permalink":"/wiki-test/docs/NeoEdge NG4500 Series/NG4500-CB01 Development Board/Software Guide/Software Frameworks and Tools/Docker"},"next":{"title":"n8n","permalink":"/wiki-test/docs/NeoEdge NG4500 Series/NG4500-CB01 Development Board/Software Guide/Software Frameworks and Tools/n8n"}}');var r=n(74848),a=n(28453);const i={},o="Ollama",t={},d=[{value:"1.Overview",id:"1overview",level:2},{value:"2. System Requirements",id:"2-system-requirements",level:2},{value:"Hardware",id:"hardware",level:3},{value:"Software",id:"software",level:3},{value:"3. Installing Ollama",id:"3-installing-ollama",level:2},{value:"Method A: Script Installation (Recommended)",id:"method-a-script-installation-recommended",level:3},{value:"Method B: Docker-Based Installation (Optional)",id:"method-b-docker-based-installation-optional",level:3},{value:"4.Usage",id:"4usage",level:2},{value:"Common Commands",id:"common-commands",level:3},{value:"Check Version",id:"check-version",level:3},{value:"Start the Service (If Not Auto-Started)",id:"start-the-service-if-not-auto-started",level:3},{value:"5.  (Optional) Enable Remote Access",id:"5--optional-enable-remote-access",level:2},{value:"6. Running",id:"6-running",level:2},{value:"7. Update",id:"7-update",level:2},{value:"(Optional) Install a Specific Version",id:"optional-install-a-specific-version",level:3},{value:"8. Uninstall",id:"8-uninstall",level:2},{value:"Stop and Remove the System Service",id:"stop-and-remove-the-system-service",level:3},{value:"Remove the Executable",id:"remove-the-executable",level:3},{value:"Delete Model Files and User Account",id:"delete-model-files-and-user-account",level:3},{value:"9. Troubleshooting",id:"9-troubleshooting",level:2},{value:"10. Appendix",id:"10-appendix",level:2},{value:"Path References",id:"path-references",level:3},{value:"References",id:"references",level:3}];function c(e){const l={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(l.header,{children:(0,r.jsx)(l.h1,{id:"ollama",children:"Ollama"})}),"\n",(0,r.jsx)(l.hr,{}),"\n",(0,r.jsxs)(l.p,{children:["This guide describes how to install, update, configure, and uninstall ",(0,r.jsx)(l.strong,{children:"Ollama"})," on ",(0,r.jsx)(l.strong,{children:"NVIDIA Jetson Orin"})," devices. Ollama enables local inference for large language models (LLMs) with CUDA acceleration, and is optimized specifically for Jetson hardware."]}),"\n",(0,r.jsx)(l.hr,{}),"\n",(0,r.jsx)(l.h2,{id:"1overview",children:"1.Overview"}),"\n",(0,r.jsxs)(l.ul,{children:["\n",(0,r.jsx)(l.li,{children:"Fast local LLM inference"}),"\n",(0,r.jsx)(l.li,{children:"CUDA acceleration support"}),"\n",(0,r.jsx)(l.li,{children:"Built-in model version management"}),"\n",(0,r.jsx)(l.li,{children:"Simple CLI tool with optional WebUI"}),"\n"]}),"\n",(0,r.jsx)(l.p,{children:"This guide covers:"}),"\n",(0,r.jsxs)(l.ul,{children:["\n",(0,r.jsx)(l.li,{children:"Installation via script or Docker"}),"\n",(0,r.jsx)(l.li,{children:"Running models"}),"\n",(0,r.jsx)(l.li,{children:"Updating Ollama and models"}),"\n",(0,r.jsx)(l.li,{children:"Optional remote access setup"}),"\n",(0,r.jsx)(l.li,{children:"Complete uninstallation procedure"}),"\n"]}),"\n",(0,r.jsx)(l.p,{children:(0,r.jsx)(l.img,{alt:"overview",src:n(98940).A+"",width:"879",height:"376"})}),"\n",(0,r.jsx)(l.hr,{}),"\n",(0,r.jsx)(l.h2,{id:"2-system-requirements",children:"2. System Requirements"}),"\n",(0,r.jsx)(l.h3,{id:"hardware",children:"Hardware"}),"\n",(0,r.jsxs)(l.table,{children:[(0,r.jsx)(l.thead,{children:(0,r.jsxs)(l.tr,{children:[(0,r.jsx)(l.th,{children:"Component"}),(0,r.jsx)(l.th,{children:"Minimum Requirement"})]})}),(0,r.jsxs)(l.tbody,{children:[(0,r.jsxs)(l.tr,{children:[(0,r.jsx)(l.td,{children:"Device"}),(0,r.jsx)(l.td,{children:"Jetson Orin Nano / NX"})]}),(0,r.jsxs)(l.tr,{children:[(0,r.jsx)(l.td,{children:"Memory"}),(0,r.jsx)(l.td,{children:"\u2265 8GB (for running small to medium models)"})]}),(0,r.jsxs)(l.tr,{children:[(0,r.jsx)(l.td,{children:"Storage"}),(0,r.jsx)(l.td,{children:"\u2265 10GB (for model and cache storage)"})]})]})]}),"\n",(0,r.jsx)(l.h3,{id:"software",children:"Software"}),"\n",(0,r.jsxs)(l.ul,{children:["\n",(0,r.jsx)(l.li,{children:"Ubuntu 20.04 or 22.04\uff08based on JetPack\uff09"}),"\n",(0,r.jsx)(l.li,{children:"JetPack 5.1.1+ (includes CUDA, cuDNN, TensorRT)"}),"\n",(0,r.jsx)(l.li,{children:"Python 3.8+ (optional)"}),"\n",(0,r.jsx)(l.li,{children:"Docker(optional, for containerized deployment)"}),"\n"]}),"\n",(0,r.jsx)(l.hr,{}),"\n",(0,r.jsx)(l.h2,{id:"3-installing-ollama",children:"3. Installing Ollama"}),"\n",(0,r.jsx)(l.h3,{id:"method-a-script-installation-recommended",children:"Method A: Script Installation (Recommended)"}),"\n",(0,r.jsx)(l.p,{children:"Run the official installation script\uff1a"}),"\n",(0,r.jsx)(l.pre,{children:(0,r.jsx)(l.code,{className:"language-bash",children:"curl -fsSL https://ollama.com/install.sh | sh\n"})}),"\n",(0,r.jsxs)(l.ul,{children:["\n",(0,r.jsx)(l.li,{children:"Installs the CLI binary and background service."}),"\n",(0,r.jsx)(l.li,{children:"CUDA support is enabled by default on Jetson devices."}),"\n"]}),"\n",(0,r.jsx)(l.h3,{id:"method-b-docker-based-installation-optional",children:"Method B: Docker-Based Installation (Optional)"}),"\n",(0,r.jsx)(l.pre,{children:(0,r.jsx)(l.code,{className:"language-bash",children:"sudo docker run --runtime nvidia --rm --network=host \\\r\n  -v ~/ollama:/ollama \\\r\n  -e OLLAMA_MODELS=/ollama \\\r\n  dustynv/ollama:r36.4.0\n"})}),"\n",(0,r.jsxs)(l.blockquote,{children:["\n",(0,r.jsx)(l.p,{children:"\ud83e\udde9 This Docker image is maintained by Jetson community contributor dustynv, optimized for JetPack environments."}),"\n"]}),"\n",(0,r.jsx)(l.hr,{}),"\n",(0,r.jsx)(l.h2,{id:"4usage",children:"4.Usage"}),"\n",(0,r.jsx)(l.h3,{id:"common-commands",children:"Common Commands"}),"\n",(0,r.jsx)(l.pre,{children:(0,r.jsx)(l.code,{className:"language-bash",children:"ollama serve         # Start the Ollama background service  \r\nollama run           # Run a model  \r\nollama pull          # Download a model from the registry  \r\nollama list          # List installed models  \r\nollama show          # Display model information  \r\nollama rm            # Remove a model  \r\nollama help          # Show help menu\n"})}),"\n",(0,r.jsx)(l.h3,{id:"check-version",children:"Check Version"}),"\n",(0,r.jsx)(l.pre,{children:(0,r.jsx)(l.code,{className:"language-bash",children:"ollama -v\r\n# Sample\uff1aollama version 0.5.7\n"})}),"\n",(0,r.jsx)(l.h3,{id:"start-the-service-if-not-auto-started",children:"Start the Service (If Not Auto-Started)"}),"\n",(0,r.jsx)(l.pre,{children:(0,r.jsx)(l.code,{className:"language-bash",children:"ollama serve &\n"})}),"\n",(0,r.jsx)(l.hr,{}),"\n",(0,r.jsx)(l.h2,{id:"5--optional-enable-remote-access",children:"5.  (Optional) Enable Remote Access"}),"\n",(0,r.jsx)(l.p,{children:"To allow external devices to access the Ollama service:"}),"\n",(0,r.jsx)(l.p,{children:"1.Edit the systemd service file\uff1a"}),"\n",(0,r.jsx)(l.pre,{children:(0,r.jsx)(l.code,{className:"language-bash",children:"sudo nano /etc/systemd/system/ollama.service\n"})}),"\n",(0,r.jsxs)(l.ol,{start:"2",children:["\n",(0,r.jsxs)(l.li,{children:["\n",(0,r.jsxs)(l.p,{children:["Add the following lines under the ",(0,r.jsx)(l.code,{children:"[Service]"})," section:"]}),"\n",(0,r.jsx)(l.pre,{children:(0,r.jsx)(l.code,{className:"language-ini",children:'Environment="OLLAMA_HOST=0.0.0.0"\r\nEnvironment="OLLAMA_ORIGINS=*"\n'})}),"\n"]}),"\n",(0,r.jsxs)(l.li,{children:["\n",(0,r.jsx)(l.p,{children:"Reload and restart the service:"}),"\n",(0,r.jsx)(l.pre,{children:(0,r.jsx)(l.code,{className:"language-bash",children:"sudo systemctl daemon-reload\r\nsudo systemctl restart ollama\n"})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(l.hr,{}),"\n",(0,r.jsx)(l.h2,{id:"6-running",children:"6. Running"}),"\n",(0,r.jsxs)(l.p,{children:["Use the  ",(0,r.jsx)(l.code,{children:"ollama run"})," command to start model inference:"]}),"\n",(0,r.jsx)(l.pre,{children:(0,r.jsx)(l.code,{className:"language-bash",children:"ollama run deepseek-r1:7b\n"})}),"\n",(0,r.jsxs)(l.ul,{children:["\n",(0,r.jsxs)(l.li,{children:["More available models refer to\uff1a",(0,r.jsx)(l.a,{href:"https://ollama.com/search",children:"https://ollama.com/search"})]}),"\n",(0,r.jsx)(l.li,{children:"The model will be downloaded on first run and cached locally for future use."}),"\n"]}),"\n",(0,r.jsx)(l.hr,{}),"\n",(0,r.jsx)(l.h2,{id:"7-update",children:"7. Update"}),"\n",(0,r.jsx)(l.p,{children:"Update to the Latest Version\uff1a"}),"\n",(0,r.jsx)(l.pre,{children:(0,r.jsx)(l.code,{className:"language-bash",children:"curl -fsSL https://ollama.com/install.sh | sh\n"})}),"\n",(0,r.jsx)(l.h3,{id:"optional-install-a-specific-version",children:"(Optional) Install a Specific Version"}),"\n",(0,r.jsx)(l.p,{children:"To install a specific version, specify the version number like this\uff1a"}),"\n",(0,r.jsx)(l.pre,{children:(0,r.jsx)(l.code,{className:"language-bash",children:"curl -fsSL https://ollama.com/install.sh | OLLAMA_VERSION=0.1.32 sh\n"})}),"\n",(0,r.jsx)(l.hr,{}),"\n",(0,r.jsx)(l.h2,{id:"8-uninstall",children:"8. Uninstall"}),"\n",(0,r.jsx)(l.h3,{id:"stop-and-remove-the-system-service",children:"Stop and Remove the System Service"}),"\n",(0,r.jsx)(l.pre,{children:(0,r.jsx)(l.code,{className:"language-bash",children:"sudo systemctl stop ollama\r\nsudo systemctl disable ollama\r\nsudo rm /etc/systemd/system/ollama.service\n"})}),"\n",(0,r.jsx)(l.h3,{id:"remove-the-executable",children:"Remove the Executable"}),"\n",(0,r.jsx)(l.pre,{children:(0,r.jsx)(l.code,{className:"language-bash",children:"sudo rm $(which ollama)\n"})}),"\n",(0,r.jsxs)(l.p,{children:["\uff08Note: Ollama is typically installed in",(0,r.jsx)(l.code,{children:"/usr/local/bin"}),"\u3001",(0,r.jsx)(l.code,{children:"/usr/bin"})," or ",(0,r.jsx)(l.code,{children:"/bin"}),"\uff09"]}),"\n",(0,r.jsx)(l.h3,{id:"delete-model-files-and-user-account",children:"Delete Model Files and User Account"}),"\n",(0,r.jsx)(l.pre,{children:(0,r.jsx)(l.code,{className:"language-bash",children:"sudo rm -r /usr/share/ollama\r\nsudo userdel ollama\r\nsudo groupdel ollama\n"})}),"\n",(0,r.jsx)(l.hr,{}),"\n",(0,r.jsx)(l.h2,{id:"9-troubleshooting",children:"9. Troubleshooting"}),"\n",(0,r.jsxs)(l.table,{children:[(0,r.jsx)(l.thead,{children:(0,r.jsxs)(l.tr,{children:[(0,r.jsx)(l.th,{children:"Issue"}),(0,r.jsx)(l.th,{children:"Solution"})]})}),(0,r.jsxs)(l.tbody,{children:[(0,r.jsxs)(l.tr,{children:[(0,r.jsx)(l.td,{children:"Port 11434 not responding"}),(0,r.jsxs)(l.td,{children:["Restart",(0,r.jsx)(l.code,{children:"ollama serve"})," or reload the system service"]})]}),(0,r.jsxs)(l.tr,{children:[(0,r.jsx)(l.td,{children:"Installation failed"}),(0,r.jsxs)(l.td,{children:["Ensure curl is installed and you have internet access; try using  ",(0,r.jsx)(l.code,{children:"sudo"})]})]}),(0,r.jsxs)(l.tr,{children:[(0,r.jsx)(l.td,{children:"Unable to uninstall Ollamaollama"}),(0,r.jsxs)(l.td,{children:["Use ",(0,r.jsx)(l.code,{children:"which ollama"}),"  to locate the actual path, then delete it manually"]})]}),(0,r.jsxs)(l.tr,{children:[(0,r.jsx)(l.td,{children:"Out of Memory (OOM) error"}),(0,r.jsxs)(l.td,{children:["Try using a smaller model \uff08e.g., ",(0,r.jsx)(l.code,{children:"1.5b"})," or ",(0,r.jsx)(l.code,{children:"7b"}),"\uff09\uff0cor add swap space"]})]})]})]}),"\n",(0,r.jsx)(l.hr,{}),"\n",(0,r.jsx)(l.h2,{id:"10-appendix",children:"10. Appendix"}),"\n",(0,r.jsx)(l.h3,{id:"path-references",children:"Path References"}),"\n",(0,r.jsxs)(l.table,{children:[(0,r.jsx)(l.thead,{children:(0,r.jsxs)(l.tr,{children:[(0,r.jsx)(l.th,{children:"Purpose"}),(0,r.jsx)(l.th,{children:"Path"})]})}),(0,r.jsxs)(l.tbody,{children:[(0,r.jsxs)(l.tr,{children:[(0,r.jsx)(l.td,{children:"Ollama executable"}),(0,r.jsx)(l.td,{children:(0,r.jsx)(l.code,{children:"/usr/local/bin/ollama"})})]}),(0,r.jsxs)(l.tr,{children:[(0,r.jsx)(l.td,{children:"Model cache"}),(0,r.jsxs)(l.td,{children:[(0,r.jsx)(l.code,{children:"~/ollama/"})," or",(0,r.jsx)(l.code,{children:"/usr/share/ollama"})]})]}),(0,r.jsxs)(l.tr,{children:[(0,r.jsx)(l.td,{children:"Service configuration"}),(0,r.jsx)(l.td,{children:(0,r.jsx)(l.code,{children:"/etc/systemd/system/ollama.service"})})]})]})]}),"\n",(0,r.jsx)(l.h3,{id:"references",children:"References"}),"\n",(0,r.jsxs)(l.ul,{children:["\n",(0,r.jsx)(l.li,{children:(0,r.jsx)(l.a,{href:"https://ollama.com/",children:"Ollama  Official Website"})}),"\n",(0,r.jsx)(l.li,{children:(0,r.jsx)(l.a,{href:"https://github.com/ollama/ollama",children:"Ollama GitHub Repository"})}),"\n",(0,r.jsx)(l.li,{children:(0,r.jsx)(l.a,{href:"https://forums.developer.nvidia.com/",children:"NVIDIA Jetson Community Forum"})}),"\n"]})]})}function h(e={}){const{wrapper:l}={...(0,a.R)(),...e.components};return l?(0,r.jsx)(l,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},98940:(e,l,n)=>{n.d(l,{A:()=>s});const s=n.p+"assets/images/NG45XX_ollama_overview-f31890e3ed61ef9d1b96bade493a5d82.png"},28453:(e,l,n)=>{n.d(l,{R:()=>i,x:()=>o});var s=n(96540);const r={},a=s.createContext(r);function i(e){const l=s.useContext(a);return s.useMemo((function(){return"function"==typeof e?e(l):{...l,...e}}),[l,e])}function o(e){let l;return l=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),s.createElement(a.Provider,{value:l},e.children)}}}]);