"use strict";(self.webpackChunkclassic=self.webpackChunkclassic||[]).push([[8518],{14420:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>s,metadata:()=>r,toc:()=>a});const r=JSON.parse('{"id":"NeoEdge NG4500 Series/Application Guide/Object Detection","title":"Object Detection","description":"---","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/1-NeoEdge NG4500 Series/3-Application Guide/3-Object Detection.md","sourceDirName":"1-NeoEdge NG4500 Series/3-Application Guide","slug":"/NeoEdge NG4500 Series/Application Guide/Object Detection","permalink":"/wiki-test/docs/NeoEdge NG4500 Series/Application Guide/Object Detection","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Pose Estimation","permalink":"/wiki-test/docs/NeoEdge NG4500 Series/Application Guide/mediapipe"},"next":{"title":"Product Information","permalink":"/wiki-test/docs/NeoEyes NE101 Series/Overview"}}');var i=t(74848),l=t(28453);const s={},o="Object Detection",c={},a=[{value:"1. Overview",id:"1-overview",level:2},{value:"2. Environment Preparation",id:"2-environment-preparation",level:2},{value:"Hardware Support",id:"hardware-support",level:3},{value:"3. Quick Start via Docker\uff08Recommended\uff09",id:"3-quick-start-via-dockerrecommended",level:2},{value:"4. Local Installation YOLOv11 (Optional)",id:"4-local-installation-yolov11-optional",level:2},{value:"Step 1: Set Up the Python Environment",id:"step-1-set-up-the-python-environment",level:3},{value:"Step 2: Install the YOLOv11 Package",id:"step-2-install-the-yolov11-package",level:3},{value:"Step 3: Install Compatible PyTorch and Torchvision",id:"step-3-install-compatible-pytorch-and-torchvision",level:3},{value:"Step 4: Install ONNX Runtime (GPU)",id:"step-4-install-onnx-runtime-gpu",level:3},{value:"5. Accelerating YOLOv11 Inference with TensorRT",id:"5-accelerating-yolov11-inference-with-tensorrt",level:2},{value:"Python Example",id:"python-example",level:3},{value:"CLI Example",id:"cli-example",level:3},{value:"6. Using DLA (Deep Learning Accelerator)",id:"6-using-dla-deep-learning-accelerator",level:2},{value:"Python Example",id:"python-example-1",level:3},{value:"CLI Example",id:"cli-example-1",level:3},{value:"7\u3001object detection Example",id:"7object-detection-example",level:2},{value:"yolo_od",id:"yolo_od",level:2},{value:"7. Benchmark Performance Comparison",id:"7-benchmark-performance-comparison",level:2},{value:"8. Optimization Tips",id:"8-optimization-tips",level:2},{value:"9. Troubleshooting",id:"9-troubleshooting",level:2},{value:"References",id:"references",level:2}];function d(e){const n={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"object-detection",children:"Object Detection"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"1-overview",children:"1. Overview"}),"\n",(0,i.jsx)(n.p,{children:"YOLOv11 is the latest-generation object detection model released by Ultralytics, delivering an exceptional balance between speed and accuracy. When deployed locally on NVIDIA Jetson devices (such as Orin Nano, NX, or AGX), YOLOv11 enables efficient, low-latency AI inference optimized for edge environments."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"yolo_overview",src:t(3338).A+"",width:"922",height:"367"})}),"\n",(0,i.jsx)(n.p,{children:"This guide covers:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Preparing the environment and installing JetPack"}),"\n",(0,i.jsx)(n.li,{children:"Running YOLOv11 quickly using Docker"}),"\n",(0,i.jsx)(n.li,{children:"Installing YOLOv11 and its dependencies locally"}),"\n",(0,i.jsx)(n.li,{children:"Accelerating inference with TensorRT"}),"\n",(0,i.jsx)(n.li,{children:"Leveraging DLA acceleration and benchmarking performance"}),"\n"]}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:"YOLOv11 runs exceptionally well on devices such as the Jetson Orin Nano, offering a powerful solution for real-time edge AI deployment."}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"2-environment-preparation",children:"2. Environment Preparation"}),"\n",(0,i.jsx)(n.h3,{id:"hardware-support",children:"Hardware Support"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Device"}),(0,i.jsx)(n.th,{children:"Supported JetPack Version"}),(0,i.jsx)(n.th,{children:"AI Performance"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Jetson Nano"}),(0,i.jsx)(n.td,{children:"JetPack 4.6.x"}),(0,i.jsx)(n.td,{children:"472 GFLOPS"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Jetson Xavier NX"}),(0,i.jsx)(n.td,{children:"JetPack 5.1.x"}),(0,i.jsx)(n.td,{children:"21 TOPS"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Jetson Orin NX 16GB"}),(0,i.jsx)(n.td,{children:"JetPack 6.x"}),(0,i.jsx)(n.td,{children:"100 TOPS"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Jetson Orin Nano Super"}),(0,i.jsx)(n.td,{children:"JetPack 6.x"}),(0,i.jsx)(n.td,{children:"67 TOPS"})]})]})]}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:"For optimal results, it is recommended to use JetPack 5.1 or later and enable maximum performance mode\uff1a"}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"sudo nvpmodel -m 0\r\nsudo jetson_clocks\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"3-quick-start-via-dockerrecommended",children:"3. Quick Start via Docker\uff08Recommended\uff09"}),"\n",(0,i.jsx)(n.p,{children:"The fastest way to get started is by using the prebuilt Docker image provided by Ultralytics. Run the following commands:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"sudo docker pull ultralytics/ultralytics:latest-jetson-jetpack6\r\nsudo docker run -it --ipc=host --runtime=nvidia ultralytics/ultralytics:latest-jetson-jetpack6\n"})}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:"Includes YOLOv11, PyTorch, Torchvision, TensorRT, and other required dependencies."}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"4-local-installation-yolov11-optional",children:"4. Local Installation YOLOv11 (Optional)"}),"\n",(0,i.jsx)(n.p,{children:"This option is intended for users who need a customized environment."}),"\n",(0,i.jsx)(n.h3,{id:"step-1-set-up-the-python-environment",children:"Step 1: Set Up the Python Environment"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"sudo apt update\r\nsudo apt install python3-pip -y\r\npip install -U pip\n"})}),"\n",(0,i.jsx)(n.h3,{id:"step-2-install-the-yolov11-package",children:"Step 2: Install the YOLOv11 Package"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"pip install ultralytics[export]\n"})}),"\n",(0,i.jsx)(n.h3,{id:"step-3-install-compatible-pytorch-and-torchvision",children:"Step 3: Install Compatible PyTorch and Torchvision"}),"\n",(0,i.jsxs)(n.p,{children:["While ",(0,i.jsx)(n.code,{children:"ultralytics"})," automatically installs PyTorch and Torchvision, the pip-installed versions are not compatible with ARM64-based Jetson platforms.Instead, you need to manually install a prebuilt PyTorch wheel and build Torchvision from source."]}),"\n",(0,i.jsx)(n.p,{children:"Example: JetPack 6.1 + Python 3.10"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"pip install https://github.com/ultralytics/assets/releases/download/v0.0.0/torch-2.5.0a0+872d972e41.nv24.08-cp310-cp310-linux_aarch64.whl\r\npip install https://github.com/ultralytics/assets/releases/download/v0.0.0/torchvision-0.20.0a0+afc54f7-cp310-cp310-linux_aarch64.whl\n"})}),"\n",(0,i.jsx)(n.p,{children:"Install cuSPARSELt to Resolve Torch 2.5.0 Dependency:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/arm64/cuda-keyring_1.1-1_all.deb\r\nsudo dpkg -i cuda-keyring_1.1-1_all.deb\r\nsudo apt-get update\r\nsudo apt-get -y install libcusparselt0 libcusparselt-dev\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.p,{children:"Verify PyTorch Version and GPU Availability:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'python3 -c "import torch; print(torch.__version__)" # 2.5.0a0+872d972e41.nv24.08\r\npython3 -c "import torch; print(torch.cuda.is_available())" # True\n'})}),"\n",(0,i.jsx)(n.h3,{id:"step-4-install-onnx-runtime-gpu",children:"Step 4: Install ONNX Runtime (GPU)"}),"\n",(0,i.jsxs)(n.p,{children:["To find all available ",(0,i.jsx)(n.code,{children:" onnxruntime-gpu packages"})," \u2014organized by JetPack version, Python version, and other compatibility details\u2014in the Jetson Zoo ONNX Runtime Compatibility Matrix. In this example, we will download and install ",(0,i.jsx)(n.code,{children:"onnxruntime-gpu 1.20.0 "}),"with support for Python 3.10."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"pip install https://github.com/ultralytics/assets/releases/download/v0.0.0/onnxruntime_gpu-1.20.0-cp310-cp310-linux_aarch64.whl\n"})}),"\n",(0,i.jsx)(n.h2,{id:"5-accelerating-yolov11-inference-with-tensorrt",children:"5. Accelerating YOLOv11 Inference with TensorRT"}),"\n",(0,i.jsxs)(n.p,{children:["Ultralytics supports exporting YOLOv11 models to TensorRT engine files \uff08",(0,i.jsx)(n.code,{children:".engine"}),"\uff09\uff0cto significantly improve inference performance."]}),"\n",(0,i.jsx)(n.h3,{id:"python-example",children:"Python Example"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'from ultralytics import YOLO\r\n\r\nmodel = YOLO("yolo11n.pt")\r\nmodel.export(format="engine")  # \u751f\u6210 yolo11n.engine\r\n\r\ntrt_model = YOLO("yolo11n.engine")\r\nresults = trt_model("https://ultralytics.com/images/bus.jpg")\n'})}),"\n",(0,i.jsx)(n.h3,{id:"cli-example",children:"CLI Example"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Export a YOLO11n PyTorch model to TensorRT format\r\nyolo export model=yolo11n.pt format=engine # creates 'yolo11n.engine'\r\n# Run inference with the exported model\r\nyolo predict model=yolo11n.engine source='https://ultralytics.com/images/bus.jpg'\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"6-using-dla-deep-learning-accelerator",children:"6. Using DLA (Deep Learning Accelerator)"}),"\n",(0,i.jsx)(n.p,{children:"Some Jetson devices feature built-in DLA (Deep Learning Accelerator) cores that enable lower power consumption and improved parallel inference."}),"\n",(0,i.jsx)(n.h3,{id:"python-example-1",children:"Python Example"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'model.export(format="engine", device="dla:0", half=True)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"cli-example-1",children:"CLI Example"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Export a YOLO11n PyTorch model to TensorRT format with DLA enabled (only works with FP16 or INT8)\r\n# Once DLA core number is specified at export, it will use the same core at inference\r\nyolo export model=yolo11n.pt format=engine device=\"dla:0\" half=True # dla:0 or dla:1 corresponds to the DLA cores\r\n# Run inference with the exported model on the DLA\r\nyolo predict model=yolo11n.engine source='https://ultralytics.com/images/bus.jpg'\n"})}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:"Note: Some model layers may not run entirely on the DLA and will fall back to GPU execution if unsupported."}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"7object-detection-example",children:"7\u3001object detection Example"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import cv2\r\nimport time\r\nfrom ultralytics import YOLO\r\n\r\n# Load the TensorRT engine model (exported from YOLO11)\r\nmodel = YOLO("yolo11n.engine")  # Replace with the path to your .engine model\r\n\r\n# Open the USB camera (usually /dev/video0)\r\ncap = cv2.VideoCapture(0)\r\n\r\n# Set camera resolution (match model input size for best performance)\r\ncap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\r\ncap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\r\n\r\n# Initialize FPS calculation variables\r\nfps = 0.0\r\nframe_count = 0\r\nstart_time = time.time()\r\n# Check if the camera opened successfully\r\nif not cap.isOpened():\r\n    print("\u274c Cannot open camera")\r\n    exit()\r\nprint("\ud83d\udcf8 Real-time detection started. Press \'q\' to quit.")\r\nwhile True:\r\n    # Read a frame from the camera\r\n    ret, frame = cap.read()\r\n    if not ret:\r\n        break\r\n    # Start time for inference\r\n    t0 = time.time()\r\n    # Run inference\r\n    results = model(frame)\r\n    # Plot the results (draw bounding boxes, labels, etc.)\r\n    annotated = results[0].plot()\r\n    # Calculate FPS\r\n    frame_count += 1\r\n    t1 = time.time()\r\n    fps = 1. / (t1 - t0)\r\n    # Draw FPS on the frame\r\n    cv2.putText(annotated, f"FPS: {fps:.2f}", (10, 30),\r\n                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\r\n    # Show the annotated frame\r\n    cv2.imshow("YOLO11 - TensorRT Real-time Detection", annotated)\r\n    # Exit on \'q\' key press\r\n    if cv2.waitKey(1) & 0xFF == ord("q"):\r\n        break\r\n# Release camera and close display window\r\ncap.release()\r\ncv2.destroyAllWindows()\n'})}),"\n",(0,i.jsx)(n.h2,{id:"yolo_od",children:(0,i.jsx)(n.img,{alt:"yolo_od",src:t(47490).A+"",width:"1920",height:"1080"})}),"\n",(0,i.jsx)(n.h2,{id:"7-benchmark-performance-comparison",children:"7. Benchmark Performance Comparison"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Model  Format"}),(0,i.jsx)(n.th,{children:"Orin Nano\uff08ms\uff09"}),(0,i.jsx)(n.th,{children:"mAP50-95"}),(0,i.jsx)(n.th,{children:"Orin NX\uff08ms\uff09"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"PyTorch"}),(0,i.jsx)(n.td,{children:"21.3"}),(0,i.jsx)(n.td,{children:"0.6176"}),(0,i.jsx)(n.td,{children:"19.5"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"TorchScript"}),(0,i.jsx)(n.td,{children:"13.4"}),(0,i.jsx)(n.td,{children:"0.6100"}),(0,i.jsx)(n.td,{children:"13.03"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"TensorRT (FP16)"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"4.91"})}),(0,i.jsx)(n.td,{children:"0.6096"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"4.85"})})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"TensorRT (INT8)"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"3.91"})}),(0,i.jsx)(n.td,{children:"0.3180"}),(0,i.jsx)(n.td,{children:"4.37"})]})]})]}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:"\u2705 TensorRT (FP16) achieves the best balance between speed and accuracy. \u26a0\ufe0f INT8 offers the fastest inference speed but with a significant accuracy drop."}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"8-optimization-tips",children:"8. Optimization Tips"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Optimization"}),(0,i.jsx)(n.th,{children:"Recommended Command"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Power Mode"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"sudo nvpmodel -m 0"})})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"CPU/GPU Frequency"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"sudo jetson_clocks"})})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"System Monitoring"}),(0,i.jsxs)(n.td,{children:[(0,i.jsx)(n.code,{children:"sudo pip install jetson-stats"})," \u2192 ",(0,i.jsx)(n.code,{children:"jtop"})]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Memory Management"}),(0,i.jsx)(n.td,{children:"Use swap efficiently, clean cache when needed"})]})]})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"9-troubleshooting",children:"9. Troubleshooting"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Issues"}),(0,i.jsx)(n.th,{children:"Solution"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Cannot import PyTorch after installation"}),(0,i.jsxs)(n.td,{children:["Make sure you're using the  ",(0,i.jsx)(n.code,{children:".whl"})," package specifically built for Jetson"]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"TensorRT  inference is slower than expected"}),(0,i.jsxs)(n.td,{children:["Check if ",(0,i.jsx)(n.code,{children:"jetson_clocks"})," is enabled and use FP16 mode"]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Failed to pull Docker image"}),(0,i.jsxs)(n.td,{children:["Ensure Docker is properly installed and run with ",(0,i.jsx)(n.code,{children:"--runtime=nvidia"})]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"No module named 'tensorrt' in virtual env"}),(0,i.jsxs)(n.td,{children:["Copy the package from host to venv: ",(0,i.jsx)(n.code,{children:"cp -r /usr/lib/python3.10/dist-packages/tensorrt your_venv/lib/python3.10/site-packages/"})]})]})]})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://docs.ultralytics.com/",children:"Ultralytics YOLO11 Documentation"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://forums.developer.nvidia.com/",children:"NVIDIA Jetson Developer Forum"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://forums.developer.nvidia.com/t/pytorch-for-jetson-version-1-14-now-available/72048",children:"PyTorch for Jetson Support"})}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},47490:(e,n,t)=>{t.d(n,{A:()=>r});const r=t.p+"assets/images/yolo_od-82baf6b690064499672f9464dbf5dd9d.png"},3338:(e,n,t)=>{t.d(n,{A:()=>r});const r=t.p+"assets/images/yolo_overview-f2ab43829aa3c2cb450a45f1ba698173.png"},28453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>o});var r=t(96540);const i={},l=r.createContext(i);function s(e){const n=r.useContext(l);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),r.createElement(l.Provider,{value:n},e.children)}}}]);